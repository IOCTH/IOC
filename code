# -*- coding: utf-8 -*-


import requests
from datetime import date
from datetime import timedelta
from datetime import datetime
import json
import os
import sys
import re
import tldextract
import base64

def main():
    today = date.today()
    yesterday = today - timedelta(days = 1)
    filename="URL_IOC_"+str(datetime.today().strftime('%Y-%m-%d %H'))+".txt"
    
    check_if_files_exists("msg_content.txt")
    check_if_files_exists("URL_list.txt")
    check_if_files_exists("URL_list_last24h.txt")
    check_if_files_exists(filename)
    # Get the current date and time
    now = datetime.now()
    dates=[]
    # Print the date and time for each of the past 24 hours
    for i in range(24):
    # Subtract one hour from the current time for each iteration
        past_time = now - timedelta(hours=i+1)
        # Format the date and time in a readable string format
        date_str = past_time.strftime('%Y-%m-%d %H')
        dates.append(date_str)
    
    response_json_urlhaus="urlhaus_response_all_data.json"

                     
    
    n = len(sys.argv)

    int_tags=[]
    for i in range(1, n):
        data_aux=sys.argv[i]
        data_aux=data_aux.replace(",","").replace(" ","")
        int_tags.append(data_aux)


    for i in int_tags:
        tag_to_search=i
        get_info_from_urlhaus(tag_to_search,response_json_urlhaus,yesterday,today, dates,filename)
       
    webhook_url="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    content=read_txtfile("msg_content.txt")
    title= str(datetime.today()) + " Results"
    color="000000"
    send_teams_message(webhook_url, content, title, color)
    

    
def get_info_from_urlhaus(tag_to_search,response_json_urlhaus, yesterday,today, dates,filename):
    print("")
    print("#########################", file=open("msg_content.txt", "a",encoding='utf8'))    
    print(tag_to_search, file=open("msg_content.txt", "a",encoding='utf8'))    
    print("#########################", file=open("msg_content.txt", "a",encoding='utf8'))    
    
    url = "https://urlhaus-api.abuse.ch/v1/tag?="
    all_data_list=[]
    
    
    payload={'tag': tag_to_search}
    files=[
    
    ]
    headers = {}
    
    response = requests.request("POST", url, headers=headers, data=payload, files=files)
    
    print (response.json(), file=open(response_json_urlhaus, "a",encoding='utf8'))
    

    today_results=0
    
    all_data=str(response.json())
    
    all_data_list=all_data.split("}, {")
    
    #print(all_data_list)
    
    print(">>>Yesterday", file=open("msg_content.txt", "a",encoding='utf8'))
    #by day yesterday
    counter_2=0
    for i in all_data_list:
        if str(yesterday) in i:
            counter_2=counter_2+1
    print("Yesterday all results for "+ tag_to_search + ": "+ str(counter_2), file=open("msg_content.txt", "a",encoding='utf8'))
    
    #by campaign yesterday
    print("All tags lookign for "+ tag_to_search, file=open("msg_content.txt", "a",encoding='utf8'))
    data_i=[]
    data_i_2=[]
    tags=[]
    unique_tags=[]
    tags_list=[]
    for i in all_data_list:
        if str(yesterday) in i:
            data_i=i.split("\'tags\':")
            data_i_2=data_i[1].split("]")
            tags=data_i_2[0].replace("[","").split(",")
            for tag in tags:
                tags_list.append(tag)
                if tag in unique_tags:
                    pass
                else:
                    unique_tags.append(tag)
            
    for unique_tag in unique_tags:
        count_tag=0
        for tag in tags_list:
            #print(tag) 
            if tag==unique_tag:
                count_tag=count_tag+1
            else:
                pass
        print(str(unique_tag) + ":" + str(count_tag), file=open("msg_content.txt", "a",encoding='utf8'))
    
    
    print("", file=open("msg_content.txt", "a",encoding='utf8'))    
    print(">>>Today", file=open("msg_content.txt", "a",encoding='utf8'))
    
    extract_urls(all_data_list,filename,tag_to_search)
    
    #by day today
    counter=0
    for i in all_data_list:
        if str(today) in i:
            counter=counter+1
    print("Total results for "+ tag_to_search + ": "+ str(counter), file=open("msg_content.txt", "a",encoding='utf8'))
    
   
                        
    #by campaign today
    print("All tags lookign for "+ tag_to_search, file=open("msg_content.txt", "a",encoding='utf8'))
    data_i=[]
    data_i_2=[]
    tags=[]
    unique_tags=[]
    tags_list=[]
    for i in all_data_list:
        if str(today) in i:
            data_i=i.split("\'tags\':")
            data_i_2=data_i[1].split("]")
            tags=data_i_2[0].replace("[","").split(",")
            for tag in tags:
                tags_list.append(tag)
                if tag in unique_tags:
                    pass
                else:
                    unique_tags.append(tag)
            
    for unique_tag in unique_tags:
        count_tag=0
        for tag in tags_list:
            #print(tag) 
            if tag==unique_tag:
                count_tag=count_tag+1
            else:
                pass
        print(str(unique_tag) + ":" + str(count_tag), file=open("msg_content.txt", "a",encoding='utf8'))
    
    
    
    

            
def send_teams_message(webhook_url:str, content:str, title:str, color:str="000000") -> int:
    """
      - Send a teams notification to the desired webhook_url
      - Returns the status code of the HTTP request
        - webhook_url : the url you got from the teams webhook configuration
        - content : your formatted notification content
        - title : the message that'll be displayed as title, and on phone notifications
        - color (optional) : hexadecimal code of the notification's top line color, default corresponds to black
    """
    response = requests.post(
        url=webhook_url,
        headers={"Content-Type": "application/json"},
        json={
            "themeColor": color,
            "summary": title,
            "sections": [{
                "activityTitle": title,
                "activitySubtitle": content
            }],
        },
    )
    return response.status_code # Should be 200

def check_if_files_exists(filename):
    if os.path.exists(filename):
        os.remove(filename)
    else:
        pass
    
def read_txtfile(filename):
       content=""
       with open(filename, "r") as f:
           for line in f.readlines():
               content=content + "\n" +line
       return content    
       print (content)
      
def extract_urls(all_data_list,filename,tag_to_search):
    
    
    url_list=[]
    for data in all_data_list:
        data_aux=data.split("\'url\': \'")
        data_aux_2=str(data_aux[1]).split(",")
        
    
        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', data_aux_2[0])
        found_url = urls[0]
        info = tldextract.extract(found_url)
        domain_name = info.domain
        suffix_name = info.suffix
        final_domain_name  = domain_name+"."+suffix_name
        if final_domain_name[-1]==".":
            final_domain_name=final_domain_name[:-1]
        else:
            pass
        url_list.append(final_domain_name)
        
    for line in url_list:
        print (line, file=open(filename, "a",encoding='utf8'))
    

    upload_to_github(url_list,filename,tag_to_search)
    extract_urls_last24h(all_data_list,tag_to_search)

def upload_to_github(url_list,filename,tag_to_search):
    githubAPIURL = "https://api.github.com/repos/tit0017/IOC/contents/"+tag_to_search+"_{}".format(filename)
# Replace "bracketcounters" with your username, replace "test-repo" with your repository name and replace "new-image.png" with the filename you want to upload from local to GitHub.

# Paste your API token here
    githubToken = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"


    with open(filename, "rb") as f:
        # Encoding "my-local-image.jpg" to base64 format
        encodedData = base64.b64encode(f.read())
    
        headers = {
            "Authorization": f'''Bearer {githubToken}''',
            "Content-type": "application/vnd.github+json"
        }
        data = {
            "message": "My commit message", # Put your commit message here.
            "content": encodedData.decode("utf-8")
        }
    
        r = requests.put(githubAPIURL, headers=headers, json=data)

def extract_urls_last24h(all_data_list,tag_to_search):
    now = datetime.now()
    dates=[]
    unique_url=[]
    filename="URL_list_last24h_"+str(datetime.today().strftime('%Y-%m-%d %H'))+".txt"
    # Print the date and time for each of the past 24 hours
    for i in range(24):
    # Subtract one hour from the current time for each iteration
        past_time = now - timedelta(hours=i)
        # Format the date and time in a readable string format
        date_str = past_time.strftime('%Y-%m-%d %H')
        dates.append(date_str)
    url_list=[] 
    print(dates)
    for date in dates:
        print(date)
        for data in all_data_list:
            if date in data:
                print (data)
                data_aux=data.split("\'url\': \'")
                data_aux_2=str(data_aux[1]).split(",")
                
            
                urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', data_aux_2[0])
                found_url = urls[0]
                info = tldextract.extract(found_url)
                domain_name = info.domain
                suffix_name = info.suffix
                final_domain_name  = domain_name+"."+suffix_name
                if final_domain_name[-1]==".":
                    final_domain_name=final_domain_name[:-1]
                else:
                    pass
                url_list.append(final_domain_name)
                print(final_domain_name)
            else:
                pass
    print(len(url_list))
    for x in url_list:
        if x in unique_url:
            pass
        else:
            unique_url.append(x)
    print(len(unique_url))    
    for line in unique_url:
        print (line, file=open(filename, "a",encoding='utf8'))
    

    
    upload_to_github(unique_url,filename,tag_to_search)    
if __name__ == "__main__":
    main()
